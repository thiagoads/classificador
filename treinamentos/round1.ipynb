{"cells":[{"cell_type":"markdown","id":"2658ef4c","metadata":{"id":"2658ef4c"},"source":["## Modelos para Classificação Textual de Manifestações"]},{"cell_type":"markdown","id":"1e1ad33d","metadata":{"id":"1e1ad33d"},"source":["> - Support Vector Machine + Bag of Words\n","> - Support Vector Machine + Word Embeddings\n","> - MLP (Multi Layer Perceptron) + Word Embeddings\n","> - BERT (Bidirectional Encoder Representations from Transformers)"]},{"cell_type":"markdown","id":"b9914bb6","metadata":{"id":"b9914bb6"},"source":["### Imports e Configurações"]},{"cell_type":"markdown","id":"4387d12d","metadata":{"id":"4387d12d"},"source":["Importação de dependências e funções utilitárias desenvolvidas para o auxílio nas atividades de tokenização, manipulação do conjunto de dados para a tarefa de classificação textual e conversão de tokens para as diferentes representações dos dados requeridas pelos modelos utilizads neste notebook."]},{"cell_type":"markdown","source":["Conectando ao drive e definindo base_path"],"metadata":{"id":"c1AmbwbsYd75"},"id":"c1AmbwbsYd75"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"-vVVVH6aWplw"},"id":"-vVVVH6aWplw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SE FOR RODAR NO GOOGLE COLAB TEM QUE COLOCAR\n","# O CAMINHO COMPLETO PARA O NOTEBOOK NO BASEPATH\n","base_path = './'\n","%cd {base_path}\n","!pwd"],"metadata":{"id":"g2vvbqXoWygc"},"id":"g2vvbqXoWygc","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instalando dependências necessárias"],"metadata":{"id":"nAVLQeRIYsUK"},"id":"nAVLQeRIYsUK"},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"Z-FlEeCLWZ4E"},"id":"Z-FlEeCLWZ4E","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Imports necessários"],"metadata":{"id":"EUWZpMoHY3ng"},"id":"EUWZpMoHY3ng"},{"cell_type":"code","execution_count":null,"id":"db3eb6cf","metadata":{"id":"db3eb6cf"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import spacy #TODO resolver erro ao importar lib localmente\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from nltk.stem import RSLPStemmer\n","from gensim.models import Word2Vec\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.svm import SVC\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from tensorflow.keras.optimizers import Adam\n","from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n","\n","from utils.plotting import print_confusion_matrix_as_table\n","from utils.tokenization import MyCustomTokenizer, extract_vocabulary_from_tokens\n","from utils.dataframes import compute_tokenized_columns_in_dataframe, mapping_str_class_to_target\n","from utils.embeddings import calculate_dimension_of_sentences, convert_tokens_to_embeddings, apply_average_in_embeddings, apply_padding_in_embeddings"]},{"cell_type":"markdown","id":"d96266ab","metadata":{"id":"d96266ab"},"source":["Configurações globais"]},{"cell_type":"code","execution_count":null,"id":"d4420067","metadata":{"id":"d4420067"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","nltk.download('rslp')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","plt.style.use('classic')"]},{"cell_type":"markdown","source":["### Parâmetros do Experimento"],"metadata":{"id":"orYNlfCUAHkJ"},"id":"orYNlfCUAHkJ"},{"cell_type":"code","source":["EXP_ID = '/exp01'\n","EXP_DATASET_ID = '/01'\n","EXP_SEED = 42\n","EXP_SAMPLER_STRATEGY = None # 'not minority' | 'not majority' | None\n","EXP_SAMPLER_CLASS = None # RandomUnderSampler | RandomOverSampler | None\n","EXP_DESCRIPTION = 'Descrição do Experimento'"],"metadata":{"id":"OTnKHCJUAShZ"},"id":"OTnKHCJUAShZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Criando diretórios do experimento"],"metadata":{"id":"JFZgXLSetQSs"},"id":"JFZgXLSetQSs"},{"cell_type":"code","source":["import os\n","path_to_results = '../results'\n","path_to_folder = path_to_results + EXP_ID\n","path_to_images = path_to_folder + '/images'\n","path_to_reports = path_to_folder + '/reports'\n","path_to_models = path_to_folder + '/models'\n","path_to_params = path_to_folder + '/params'\n","path_to_history = path_to_folder + '/history'\n","path_to_cmatrix = path_to_folder + '/cmatrix'\n","\n","if os.path.isdir(path_to_folder) == False:\n","  os.mkdir(path_to_folder)\n","  os.mkdir(path_to_images)\n","  os.mkdir(path_to_reports)\n","  os.mkdir(path_to_models)\n","  os.mkdir(path_to_params)\n","  os.mkdir(path_to_history)\n","  os.mkdir(path_to_cmatrix)\n","  print('Diretório {} criado com sucesso!'.format(path_to_folder))\n","else:\n","  print('Diretório {} já existe!'.format(path_to_folder))"],"metadata":{"id":"yRjoc3KTtXJ4"},"id":"yRjoc3KTtXJ4","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"a77682c8","metadata":{"id":"a77682c8"},"source":["### Carregamento dos dados"]},{"cell_type":"markdown","id":"66366ea5","metadata":{"id":"66366ea5"},"source":["Carregando dados das manifestações utilizadas no treinamento do classificador atual."]},{"cell_type":"code","execution_count":null,"id":"ad13f05e","metadata":{"id":"ad13f05e"},"outputs":[],"source":["# CONFIGUAR CAMINHO PARA CONJUNTOS DE TREINAMENTO, VALIDAÇÃO E TESTE\n","path_to_dataset = '../dataset' + EXP_DATASET_ID\n","\n","train = pd.read_csv(path_to_dataset + '/train.csv', sep = ';')\n","test = pd.read_csv(path_to_dataset + '/test.csv', sep = ';')\n","valid = pd.read_csv(path_to_dataset + '/valid.csv', sep = ';')"]},{"cell_type":"code","execution_count":null,"id":"7e76c080","metadata":{"id":"7e76c080"},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"id":"633c76e1","metadata":{"id":"633c76e1"},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"id":"a5c150d6","metadata":{"id":"a5c150d6"},"outputs":[],"source":["valid.head()"]},{"cell_type":"code","execution_count":null,"id":"7db11079","metadata":{"id":"7db11079"},"outputs":[],"source":["train.info()"]},{"cell_type":"code","execution_count":null,"id":"224b46ef","metadata":{"id":"224b46ef"},"outputs":[],"source":["test.info()"]},{"cell_type":"code","execution_count":null,"id":"6ad8140c","metadata":{"id":"6ad8140c"},"outputs":[],"source":["valid.info()"]},{"cell_type":"code","execution_count":null,"id":"02e0e06b","metadata":{"id":"02e0e06b"},"outputs":[],"source":["train['Assunto'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"f24938fc","metadata":{"id":"f24938fc"},"outputs":[],"source":["test['Assunto'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"92b259ad","metadata":{"id":"92b259ad"},"outputs":[],"source":["valid['Assunto'].value_counts()"]},{"cell_type":"markdown","id":"4fd127aa","metadata":{"id":"4fd127aa"},"source":["### Tratamento dos dados"]},{"cell_type":"markdown","id":"9e4fa93e","metadata":{"id":"9e4fa93e"},"source":["Identificando e removendo dados faltantes"]},{"cell_type":"code","execution_count":null,"id":"e42f5f41","metadata":{"id":"e42f5f41"},"outputs":[],"source":["train.isna().sum()"]},{"cell_type":"code","execution_count":null,"id":"8cd5de34","metadata":{"id":"8cd5de34"},"outputs":[],"source":["test.isna().sum()"]},{"cell_type":"code","execution_count":null,"id":"24be61c4","metadata":{"id":"24be61c4"},"outputs":[],"source":["valid.isna().sum()"]},{"cell_type":"code","execution_count":null,"id":"752afbb1","metadata":{"id":"752afbb1"},"outputs":[],"source":["train.dropna(inplace=True)\n","test.dropna(inplace=True)\n","valid.dropna(inplace=True)"]},{"cell_type":"code","execution_count":null,"id":"5ba66bd1","metadata":{"id":"5ba66bd1"},"outputs":[],"source":["train['Texto'] = train['Texto'].astype('string')\n","train['Assunto'] = train['Assunto'].astype('string')\n","test['Texto'] = test['Texto'].astype('string')\n","test['Assunto'] = test['Assunto'].astype('string')\n","valid['Texto'] = valid['Texto'].astype('string')\n","valid['Assunto'] = valid['Assunto'].astype('string')"]},{"cell_type":"code","execution_count":null,"id":"92b12846","metadata":{"id":"92b12846"},"outputs":[],"source":["train.info()"]},{"cell_type":"code","execution_count":null,"id":"98eddee3","metadata":{"id":"98eddee3"},"outputs":[],"source":["test.info()"]},{"cell_type":"code","execution_count":null,"id":"c8c84f69","metadata":{"id":"c8c84f69"},"outputs":[],"source":["valid.info()"]},{"cell_type":"code","execution_count":null,"id":"54252869","metadata":{"id":"54252869"},"outputs":[],"source":["!pip install unidecode\n","from unidecode import unidecode\n","\n","print(sorted(train['Assunto'].unique()))\n","print(sorted(test['Assunto'].unique()))\n","print(sorted(valid['Assunto'].unique()))\n","\n","def remove_accent(val):\n","    return unidecode(val)\n","\n","train['Assunto'] = train['Assunto'].apply(remove_accent)\n","test['Assunto'] = test['Assunto'].apply(remove_accent)\n","valid['Assunto'] = valid['Assunto'].apply(remove_accent)\n","\n","print(sorted(train['Assunto'].unique()))\n","print(sorted(test['Assunto'].unique()))\n","print(sorted(valid['Assunto'].unique()))"]},{"cell_type":"markdown","id":"c9bb383c","metadata":{"id":"c9bb383c"},"source":["### Divisão do dados"]},{"cell_type":"code","execution_count":null,"id":"2bfe7249","metadata":{"id":"2bfe7249"},"outputs":[],"source":["print('Total de exemplos no conjunto de treino:', len(train))\n","print('Total de exemplos no conjunto de teste :', len(test))\n","print('Total de exemplos no conjunto de valid :', len(valid))"]},{"cell_type":"markdown","id":"9eab2898","metadata":{"id":"9eab2898"},"source":["### Pré-processamento"]},{"cell_type":"code","execution_count":null,"id":"fda1f3c6","metadata":{"id":"fda1f3c6"},"outputs":[],"source":["stopwords = nltk.corpus.stopwords.words('portuguese')\n","stemmer = RSLPStemmer()"]},{"cell_type":"markdown","id":"19e095d8","metadata":{"id":"19e095d8"},"source":["Tokenizando dados de treinamento e teste e extraindo tokens para o vocabulário"]},{"cell_type":"code","execution_count":null,"id":"1246cbb6","metadata":{"id":"1246cbb6"},"outputs":[],"source":["train_text_tokenized, tokens = MyCustomTokenizer(stopwords = stopwords, stemmer = stemmer).tokenize(train['Texto'].values)\n","test_text_tokenized, _ = MyCustomTokenizer(stopwords = stopwords, stemmer = stemmer).tokenize(test['Texto'].values)\n","valid_text_tokenized, _ = MyCustomTokenizer(stopwords = stopwords, stemmer = stemmer).tokenize(valid['Texto'].values)"]},{"cell_type":"markdown","id":"03449082","metadata":{"id":"03449082"},"source":["Criando o vocabulário a partir dos tokens mais frequentes extraídos do conjunto de treinamento"]},{"cell_type":"code","execution_count":null,"id":"b7249794","metadata":{"id":"b7249794"},"outputs":[],"source":["# estamos usando todos os tokens\n","vocabulary = extract_vocabulary_from_tokens(tokens)"]},{"cell_type":"code","execution_count":null,"id":"75d3f0de","metadata":{"id":"75d3f0de"},"outputs":[],"source":["print('Tamanho do vocabulário:', len(vocabulary))"]},{"cell_type":"markdown","id":"d67bb899","metadata":{"id":"d67bb899"},"source":["Aqui, adicionaremos novas colunas com o identificador do assunto de cada manifestação baseado no campo *Assunto*. Os assuntos serão categorizados em ordem alfabética e o indice de cada um na lista de categorias será utilizado para definição do identificador do assunto em valor numérico. Primeiro no conjunto de treinamento e, em seguida, no de teste."]},{"cell_type":"code","execution_count":null,"id":"1e6f4a32","metadata":{"id":"1e6f4a32"},"outputs":[],"source":["train = compute_tokenized_columns_in_dataframe(train, train_text_tokenized)\n","train = mapping_str_class_to_target(train)"]},{"cell_type":"code","execution_count":null,"id":"c85d6ae4","metadata":{"id":"c85d6ae4"},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"id":"8acb8a2b","metadata":{"id":"8acb8a2b"},"outputs":[],"source":["train.describe()"]},{"cell_type":"code","execution_count":null,"id":"9ea75cee","metadata":{"id":"9ea75cee"},"outputs":[],"source":["test = compute_tokenized_columns_in_dataframe(test, test_text_tokenized, drop_size_zero = False)\n","test = mapping_str_class_to_target(test)"]},{"cell_type":"code","execution_count":null,"id":"63b67d20","metadata":{"id":"63b67d20"},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"id":"78dbd265","metadata":{"id":"78dbd265"},"outputs":[],"source":["test.describe()"]},{"cell_type":"code","execution_count":null,"id":"2688d3ae","metadata":{"id":"2688d3ae"},"outputs":[],"source":["valid = compute_tokenized_columns_in_dataframe(valid, valid_text_tokenized, drop_size_zero = False)\n","valid = mapping_str_class_to_target(valid)"]},{"cell_type":"code","execution_count":null,"id":"99e2fbb9","metadata":{"id":"99e2fbb9"},"outputs":[],"source":["valid.head()"]},{"cell_type":"code","execution_count":null,"id":"940405a2","metadata":{"id":"940405a2"},"outputs":[],"source":["valid.describe()"]},{"cell_type":"code","execution_count":null,"id":"a0c544aa","metadata":{"id":"a0c544aa"},"outputs":[],"source":["target_names = sorted(train['Assunto'].astype('string').unique())\n","print(target_names)\n","target_names_masked = ['Classe {}'.format(i) for i in range(len(target_names))]\n","print(target_names_masked)"]},{"cell_type":"markdown","id":"22be23bc","metadata":{"id":"22be23bc"},"source":["### Balanceamento"]},{"cell_type":"markdown","id":"888634d1","metadata":{"id":"888634d1"},"source":["Identificamos que o conjunto de dados possui mais assuntos de determinadas classes do que de outras. Esta distribuição dos dados pode ser bastante prejudicial para a performance dos modelos e, portanto, foi necessário ajustar o conjunto de treinamento para que o total de exemplos de cada classe fique mais balanceado ao moldes do que é feito em https://medium.com/analytics-vidhya/re-sampling-imbalanced-training-corpus-for-sentiment-analysis-c9dc97f9eae1."]},{"cell_type":"code","execution_count":null,"id":"9f5695ca","metadata":{"id":"9f5695ca"},"outputs":[],"source":["original = train['Target'].value_counts()\n","index = np.arange(len(original))\n","fig, ax = plt.subplots()\n","width = 0.35\n","ax.bar(index, original, label = 'Original')\n","ax.set_xticks(index, original.index)\n","ax.legend()\n","plt.title('Divisão das classes antes do balanceamento')\n","plt.show()\n","plt.savefig(path_to_images + '/balanceamento_antes.png')"]},{"cell_type":"code","execution_count":null,"id":"dc458696","metadata":{"id":"dc458696"},"outputs":[],"source":["train_resampled = train\n","\n","if EXP_SAMPLER_CLASS != None and EXP_SAMPLER_STRATEGY != None:\n","  sampler = EXP_SAMPLER_CLASS(sampling_strategy=EXP_SAMPLER_STRATEGY, random_state = EXP_SEED)\n","  train_resampled, _ = sampler.fit_resample(train_resampled, train_resampled['Target'])"]},{"cell_type":"code","execution_count":null,"id":"f64782e5","metadata":{"id":"f64782e5"},"outputs":[],"source":["resample = train_resampled['Target'].value_counts()\n","index = np.arange(len(original))\n","fig, ax = plt.subplots()\n","width = 0.35\n","ax.bar(index + width/2, resample, label = 'Resample')\n","ax.set_xticks(index, original.index)\n","ax.legend()\n","plt.title('Divisão das classes após o balanceamento')\n","plt.show()\n","plt.savefig(path_to_images + '/balanceamento_depois.png')"]},{"cell_type":"code","execution_count":null,"id":"44fe20c0","metadata":{"id":"44fe20c0"},"outputs":[],"source":["train = train_resampled"]},{"cell_type":"markdown","id":"ac810b98","metadata":{"id":"ac810b98"},"source":["### Bag of Words + SVM"]},{"cell_type":"markdown","id":"316b87d8","metadata":{"id":"316b87d8"},"source":["Criando Bag of Words de contagem de palavras do vocabulário"]},{"cell_type":"code","execution_count":null,"id":"343762cb","metadata":{"id":"343762cb"},"outputs":[],"source":["vectorizer = CountVectorizer(vocabulary = vocabulary, binary = False)"]},{"cell_type":"markdown","id":"a5b5441c","metadata":{"id":"a5b5441c"},"source":["Preparando conjunto de treinamento e testes"]},{"cell_type":"code","execution_count":null,"id":"5ca1ca45","metadata":{"id":"5ca1ca45"},"outputs":[],"source":["X_train = vectorizer.fit_transform(train['Texto_Processado'])\n","y_train = train['Target']\n","X_test = vectorizer.fit_transform(test['Texto_Processado'])\n","y_test = test['Target']"]},{"cell_type":"code","execution_count":null,"id":"f3d3876f","metadata":{"id":"f3d3876f"},"outputs":[],"source":["print(vectorizer.get_feature_names_out())"]},{"cell_type":"markdown","id":"17ae8310","metadata":{"id":"17ae8310"},"source":["Treinamento do classificador"]},{"cell_type":"code","execution_count":null,"id":"8c3057a1","metadata":{"id":"8c3057a1"},"outputs":[],"source":["clf1 = SVC(kernel = \"linear\", C = 1000)\n","clf1.fit(X_train, y_train)"]},{"cell_type":"markdown","id":"e81c2e1a","metadata":{"id":"e81c2e1a"},"source":["Avaliação do modelo no conjunto de teste"]},{"cell_type":"code","execution_count":null,"id":"95f19af8","metadata":{"id":"95f19af8"},"outputs":[],"source":["predicted1 = clf1.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"5615182c","metadata":{"id":"5615182c"},"outputs":[],"source":["print(metrics.classification_report(y_test, predicted1, target_names = target_names))"]},{"cell_type":"code","execution_count":null,"id":"638df346","metadata":{"id":"638df346"},"outputs":[],"source":["cmatrix1 = confusion_matrix(y_test, predicted1)\n","display = ConfusionMatrixDisplay(\n","    confusion_matrix=cmatrix1,\n","    display_labels=target_names_masked)\n","\n","fig, ax = plt.subplots()\n","ax.set_title('Matriz de Confusão para o modelo SVM utilizando Bag of Words\\n')\n","display.plot(ax = ax, xticks_rotation = 'vertical')\n","fig.savefig(path_to_images + '/matriz-confusao-svm-bow.png', bbox_inches='tight')"]},{"cell_type":"code","source":["np.save(path_to_cmatrix + '/svm_bow', cmatrix1)\n","np.load(path_to_cmatrix + '/svm_bow.npy')"],"metadata":{"id":"EgCj822hOfJc"},"id":"EgCj822hOfJc","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"5e69131f","metadata":{"id":"5e69131f"},"source":["### Embeddings + SVM"]},{"cell_type":"markdown","id":"7ff285ef","metadata":{"id":"7ff285ef"},"source":["Treinando modelo de embeddings a partir de texto tokenizado"]},{"cell_type":"code","execution_count":null,"id":"e6709c2d","metadata":{"id":"e6709c2d"},"outputs":[],"source":["embeddings = Word2Vec(train['Texto_Tokenizado'], vector_size=100, window=5, min_count=1, workers=4)"]},{"cell_type":"code","execution_count":null,"id":"1ce60f6d","metadata":{"id":"1ce60f6d"},"outputs":[],"source":["plt.boxplot(train['Numero_de_Tokens'].values, showfliers=False)\n","plt.title('Distribuição da quantidade de tokens por documento no conjunto de treinamento\\n')\n","plt.plot()\n","plt.savefig(path_to_images + '/boxplot-tokens-por-documento.png')"]},{"cell_type":"markdown","id":"5be81f2c","metadata":{"id":"5be81f2c"},"source":["Extraindo conjuntos de treinamento e teste"]},{"cell_type":"code","execution_count":null,"id":"1cbb35ad","metadata":{"id":"1cbb35ad"},"outputs":[],"source":["X_train = convert_tokens_to_embeddings(train['Texto_Tokenizado'], embeddings)\n","X_train = apply_average_in_embeddings(X_train, embeddings.vector_size)\n","y_train = train['Target']\n","\n","X_test = convert_tokens_to_embeddings(test['Texto_Tokenizado'], embeddings)\n","X_test = apply_average_in_embeddings(X_test, embeddings.vector_size)\n","y_test = test['Target']"]},{"cell_type":"code","execution_count":null,"id":"eebd88c5","metadata":{"id":"eebd88c5"},"outputs":[],"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"3c0e5cb1","metadata":{"id":"3c0e5cb1"},"outputs":[],"source":["clf2 = SVC(kernel = \"linear\", C = 1000)\n","clf2.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"276508a0","metadata":{"id":"276508a0"},"outputs":[],"source":["predicted2 = clf2.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"d0c2828b","metadata":{"id":"d0c2828b"},"outputs":[],"source":["print(metrics.classification_report(y_test, predicted2, target_names = target_names, zero_division = 0))"]},{"cell_type":"code","execution_count":null,"id":"8a463d23","metadata":{"id":"8a463d23"},"outputs":[],"source":["cmatrix2 = confusion_matrix(y_test, predicted2)\n","\n","display = ConfusionMatrixDisplay(\n","    confusion_matrix=cmatrix2,\n","    display_labels=target_names_masked)\n","\n","fig, ax = plt.subplots()\n","ax.set_title('Matriz de Confusão para o modelo SVM utilizando Word Embeddings\\n')\n","display.plot(ax = ax, xticks_rotation = 'vertical')\n","fig.savefig(path_to_images + '/matriz-confusao-svm-we.png', bbox_inches='tight')"]},{"cell_type":"code","source":["np.save(path_to_cmatrix + '/svm_we', cmatrix2)\n","np.load(path_to_cmatrix + '/svm_we.npy')"],"metadata":{"id":"7gFRYA1UQju2"},"id":"7gFRYA1UQju2","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"805e9b0e","metadata":{"id":"805e9b0e"},"source":["### Embeddings + Multilayer Perceptron"]},{"cell_type":"markdown","id":"0c2ffe5a","metadata":{"id":"0c2ffe5a"},"source":["Calculando tamanho do padding a ser aplicação no tensor de entrada da MLP e tamanho do vetor do modelo de embeddings"]},{"cell_type":"code","execution_count":null,"id":"9be14478","metadata":{"id":"9be14478"},"outputs":[],"source":["dimension = calculate_dimension_of_sentences(train['Numero_de_Tokens'])\n","vector_size = embeddings.vector_size"]},{"cell_type":"code","execution_count":null,"id":"145ea3dc","metadata":{"id":"145ea3dc"},"outputs":[],"source":["print('Tamanho da Dimensão Calculada :', dimension)\n","print('Tamanho do Vetor de Embeddings:', vector_size)"]},{"cell_type":"markdown","id":"c357fc58","metadata":{"id":"c357fc58"},"source":["Preparando conjunto de treinamento e testes"]},{"cell_type":"code","execution_count":null,"id":"5cec33b3","metadata":{"id":"5cec33b3"},"outputs":[],"source":["X_train = train['Texto_Tokenizado']\n","X_train = convert_tokens_to_embeddings(X_train, embeddings)\n","X_train = apply_padding_in_embeddings(X_train, vector_size , dimension)\n","y_train = train['Target']\n","\n","X_valid = valid['Texto_Tokenizado']\n","X_valid = convert_tokens_to_embeddings(X_valid, embeddings)\n","X_valid = apply_padding_in_embeddings(X_valid, vector_size , dimension)\n","y_valid = valid['Target']\n","\n","X_test = test['Texto_Tokenizado']\n","X_test = convert_tokens_to_embeddings(X_test, embeddings)\n","X_test = apply_padding_in_embeddings(X_test, vector_size , dimension)\n","y_test = test['Target']"]},{"cell_type":"markdown","id":"21866012","metadata":{"id":"21866012"},"source":["Definindo arquitetura e iniciando treinamento da MLP"]},{"cell_type":"code","execution_count":null,"id":"72d0e600","metadata":{"id":"72d0e600"},"outputs":[],"source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, LSTM\n","\n","model = Sequential()\n","model.add(Flatten(input_shape=(dimension, vector_size)))\n","model.add(Dense(1000, activation='relu', kernel_regularizer='l2')),\n","model.add(Dropout(0.4))\n","model.add(Dense(1000, activation='relu', kernel_regularizer='l2')),\n","model.add(Dropout(0.4))\n","model.add(Dense(1000, activation='relu', kernel_regularizer='l2')),\n","model.add(Dropout(0.4))\n","model.add(Dense(10, activation='softmax'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"2c120aeb","metadata":{"id":"2c120aeb"},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","path_to_checkpoint = '/tmp/checkpoint/mlp' + EXP_ID\n","\n","checkpoint = ModelCheckpoint(filepath=path_to_checkpoint,\n","                             save_weights_only = True,\n","                             monitor=\"val_loss\",\n","                             mode='min',\n","                             save_best_only=True)\n","callbacks = [checkpoint]\n","\n","model.compile(optimizer = Adam(4e-5), loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n","history_mlp = model.fit(X_train, y_train, epochs= 10, batch_size = 100, validation_data=(X_valid, y_valid), callbacks = callbacks)"]},{"cell_type":"code","source":["import json\n","\n","json.dump(history_mlp.history, open(path_to_history + '/mlp.json', 'w'))"],"metadata":{"id":"YAO1ANwQtJjg"},"id":"YAO1ANwQtJjg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carregando melhor modelo"],"metadata":{"id":"ENu8ldqzwNB2"},"id":"ENu8ldqzwNB2"},{"cell_type":"code","source":["model.load_weights(path_to_checkpoint)"],"metadata":{"id":"BXnAx2MawCBJ"},"id":"BXnAx2MawCBJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2f852621","metadata":{"id":"2f852621"},"source":["Avaliando modelo no conjunto de teste"]},{"cell_type":"code","execution_count":null,"id":"5964c2f7","metadata":{"id":"5964c2f7"},"outputs":[],"source":["predicted3 = model.predict(X_test)\n","predicted3 = np.argmax(predicted3, axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"8a86e2e8","metadata":{"id":"8a86e2e8"},"outputs":[],"source":["print(metrics.classification_report(y_test, predicted3, target_names = target_names, zero_division = 0))"]},{"cell_type":"code","execution_count":null,"id":"5e77dfbf","metadata":{"id":"5e77dfbf"},"outputs":[],"source":["cmatrix_mlp = confusion_matrix(y_test, predicted3)\n","\n","display = ConfusionMatrixDisplay(\n","    confusion_matrix=cmatrix_mlp,\n","    display_labels=target_names_masked)\n","\n","fig, ax = plt.subplots()\n","ax.set_title('Matriz de Confusão para o modelo MLP utilizando Word Embeddings\\n')\n","display.plot(ax = ax, xticks_rotation = 'vertical')\n","fig.savefig(path_to_images + '/matriz-confusao-mlp-we.png', bbox_inches='tight')"]},{"cell_type":"code","source":["np.save(path_to_cmatrix + '/mlp_we', cmatrix_mlp)\n","np.load(path_to_cmatrix + '/mlp_we.npy')"],"metadata":{"id":"vAJl79_5Qyfn"},"id":"vAJl79_5Qyfn","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"c7eb106c","metadata":{"id":"c7eb106c"},"source":["### BERT (Bidirectional Encoder Representations from Transformers)"]},{"cell_type":"code","execution_count":null,"id":"7a65dc31","metadata":{"id":"7a65dc31"},"outputs":[],"source":["bertimbau_huggingface_url = 'neuralmind/bert-base-portuguese-cased'"]},{"cell_type":"code","execution_count":null,"id":"5700f77a","metadata":{"id":"5700f77a"},"outputs":[],"source":["bert_tokenizer = AutoTokenizer.from_pretrained(bertimbau_huggingface_url)"]},{"cell_type":"markdown","id":"55eeab71","metadata":{"id":"55eeab71"},"source":["Como estamos realizando o finetuning de um modelo pré-treinado, temos que obedecer o formato de input dos dados usado no treinamento do modelo original, que, neste caso, foi de até 512 caracteres por sentença. O nosso dataset contém avaliações superiores a este valor e tivemos que truncar algumas dessas sentenças conforme é feito em\n","https://stackoverflow.com/questions/60551906/tensorflow-huggingface-invalid-argument-indices0-624-624-is-not-in-0."]},{"cell_type":"code","execution_count":null,"id":"b3a5351a","metadata":{"id":"b3a5351a"},"outputs":[],"source":["def truncate_text_for_bert(data, max_size = 512):\n","    truncated_text = []\n","    for i, text in enumerate(data):\n","        words = text.strip()\n","        size = len(words)\n","        out = words[0:min(size, max_size)]\n","        truncated_text.append(out)\n","    return truncated_text\n","\n","train_bert_text = truncate_text_for_bert(train['Texto'].to_list())\n","valid_bert_text = truncate_text_for_bert(valid['Texto'].to_list())\n","test_bert_text = truncate_text_for_bert(test['Texto'].to_list())"]},{"cell_type":"markdown","id":"4f574fcc","metadata":{"id":"4f574fcc"},"source":["Preparando conjunto de treinamento e teste a partir do tokenizador do bert"]},{"cell_type":"code","execution_count":null,"id":"90b34958","metadata":{"id":"90b34958"},"outputs":[],"source":["X_train = bert_tokenizer(train_bert_text, return_tensors = \"np\", padding = True)\n","y_train = train['Target']\n","X_valid = bert_tokenizer(valid_bert_text, return_tensors = \"np\", padding = True)\n","y_valid = valid['Target']\n","X_test = bert_tokenizer(test_bert_text, return_tensors = \"np\", padding = True)\n","y_test = test['Target']"]},{"cell_type":"code","execution_count":null,"id":"c21040af","metadata":{"id":"c21040af"},"outputs":[],"source":["bert_model = TFAutoModelForSequenceClassification.from_pretrained(bertimbau_huggingface_url, num_labels = 10)\n","bert_model.summary()"]},{"cell_type":"code","execution_count":null,"id":"06ebe5d2","metadata":{"id":"06ebe5d2"},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","path_to_checkpoint = '/tmp/checkpoint/bert' + EXP_ID\n","\n","checkpoint = ModelCheckpoint(filepath=path_to_checkpoint,\n","                             save_weights_only = True,\n","                             monitor=\"val_loss\",\n","                             mode='min',\n","                             save_best_only=True)\n","callbacks = [checkpoint]\n","\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n","bert_model.compile(optimizer = Adam(5e-6), loss = loss, metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"6abd22f0","metadata":{"id":"6abd22f0"},"outputs":[],"source":["history_bert = bert_model.fit(dict(X_train), y_train, validation_data = (dict(X_valid), y_valid), batch_size = 16, epochs = 4, callbacks = callbacks)"]},{"cell_type":"code","source":["import json\n","\n","json.dump(history_bert.history, open(path_to_history + '/bertimbau.json', 'w'))"],"metadata":{"id":"bG414xOkwztj"},"id":"bG414xOkwztj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_model.load_weights(path_to_checkpoint)"],"metadata":{"id":"Cro7UZW5xFC9"},"id":"Cro7UZW5xFC9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"71d0652d","metadata":{"id":"71d0652d"},"outputs":[],"source":["predicted4 = bert_model.predict(dict(X_test))['logits']\n","predicted4 = tf.nn.softmax(predicted4)\n","predicted4 = np.argmax(predicted4, axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"99109994","metadata":{"id":"99109994"},"outputs":[],"source":["print(metrics.classification_report(y_test, predicted4, target_names = target_names, zero_division = 0))"]},{"cell_type":"code","execution_count":null,"id":"726d8812","metadata":{"id":"726d8812"},"outputs":[],"source":["cmatrix_bertimbau = confusion_matrix(y_test, predicted4)\n","display = ConfusionMatrixDisplay(\n","    confusion_matrix=cmatrix_bertimbau,\n","    display_labels=target_names_masked)\n","\n","fig, ax = plt.subplots()\n","ax.set_title('Matriz de Confusão para o modelo BERTimbau\\n')\n","display.plot(ax = ax, xticks_rotation = 'vertical')\n","fig.savefig(path_to_images + '/matriz-confusao-bertimbau.png', bbox_inches='tight')"]},{"cell_type":"code","source":["np.save(path_to_cmatrix + '/bertimbau', cmatrix_bertimbau)\n","np.load(path_to_cmatrix + '/bertimbau.npy')"],"metadata":{"id":"GRK3Kv_PRCAQ"},"id":"GRK3Kv_PRCAQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Salvando modelos"],"metadata":{"id":"8JnvURhB4_vs"},"id":"8JnvURhB4_vs"},{"cell_type":"code","source":["import pickle\n","\n","path_to_svm = path_to_models + '/svm'\n","\n","path_to_svm_bow = path_to_svm + '/svm_bof.sav'\n","path_to_svm_we = path_to_svm + '/svm_we.sav'\n","if os.path.isdir(path_to_svm) == False:\n","  os.mkdir(path_to_svm)\n","pickle.dump(clf1, open(path_to_svm_bow, 'wb'))\n","pickle.dump(clf2, open(path_to_svm_we, 'wb'))"],"metadata":{"id":"OkR9RWI85N0J"},"id":"OkR9RWI85N0J","execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_mlp = path_to_models + '/mlp'\n","if os.path.isdir(path_to_mlp) == False:\n","  os.mkdir(path_to_mlp)\n","model.save(path_to_mlp + '/model.h5')"],"metadata":{"id":"bnphgtSk6irx"},"id":"bnphgtSk6irx","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ed062460","metadata":{"id":"ed062460"},"outputs":[],"source":["path_to_bert = path_to_models + '/bert'\n","bert_tokenizer.save_pretrained(path_to_bert)\n","bert_model.save_pretrained(path_to_bert)\n","#loaded_tokenizer = AutoTokenizer.from_pretrained(path_to_bert)\n","#loaded_model = TFAutoModelForSequenceClassification.from_pretrained(path_to_bert)"]},{"cell_type":"markdown","id":"9f0af086","metadata":{"id":"9f0af086"},"source":["### Preview da Execução"]},{"cell_type":"code","execution_count":null,"id":"83b91b7e","metadata":{"id":"83b91b7e"},"outputs":[],"source":["MODEL_NAMES = ['BoW_SVM', 'WE_SVM', 'WE_MLP', 'BERTimbau']\n","PREDICTS = [predicted1, predicted2, predicted3, predicted4]\n","REPORTS = []\n","\n","for index, model_name in enumerate(MODEL_NAMES):\n","    report = metrics.classification_report(y_test, PREDICTS[index], target_names = target_names, zero_division = 0, output_dict = True)\n","    REPORTS.append(report)"]},{"cell_type":"code","execution_count":null,"id":"b934ee83","metadata":{"scrolled":false,"id":"b934ee83"},"outputs":[],"source":["from IPython.display import HTML, Markdown, Latex\n","\n","Markdown(print_confusion_matrix_as_table(REPORTS, MODEL_NAMES))"]},{"cell_type":"markdown","id":"56bb4e66","metadata":{"id":"56bb4e66"},"source":["### Salvando Resultados"]},{"cell_type":"code","execution_count":null,"id":"6c32a7f2","metadata":{"id":"6c32a7f2"},"outputs":[],"source":["import json\n","\n","for index, model_name in enumerate(MODEL_NAMES):\n","    filename = path_to_reports + '/' + model_name.lower() + '.json'\n","    with open(filename, 'w') as outfile:\n","        dictionary = REPORTS[index]\n","        json.dump(dictionary, outfile)"]},{"cell_type":"markdown","source":["### Salvando Metadados"],"metadata":{"id":"wmcYRMj18sKz"},"id":"wmcYRMj18sKz"},{"cell_type":"code","source":["metadados = dict({\"experiment\" : EXP_ID,\n","             \"dataset\" : EXP_DATASET_ID,\n","             \"seed\": EXP_SEED,\n","             \"strategy\" : str(EXP_SAMPLER_STRATEGY),\n","             \"sampler\": str(EXP_SAMPLER_CLASS),\n","             \"description\": EXP_DESCRIPTION})\n","\n","path_to_metadata = path_to_params + '/metadata.json'\n","\n","with open(path_to_metadata, 'w') as outfile:\n","  json.dump(metadados, outfile)"],"metadata":{"id":"9n7pVyZv8pdI"},"id":"9n7pVyZv8pdI","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Liberando memória"],"metadata":{"id":"s_NEOXw3JPo5"},"id":"s_NEOXw3JPo5"},{"cell_type":"code","execution_count":null,"id":"da52c5a2","metadata":{"id":"da52c5a2"},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","source":["import IPython\n","app = IPython.Application.instance()\n","app.kernel.do_shutdown(True)"],"metadata":{"id":"wBa2kmBq-BiU"},"id":"wBa2kmBq-BiU","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EZZEzDS-GNkv"},"id":"EZZEzDS-GNkv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"collapsed_sections":["b9914bb6","orYNlfCUAHkJ","JFZgXLSetQSs","a77682c8","4fd127aa","c9bb383c","9eab2898","22be23bc","ac810b98","5e69131f","805e9b0e","c7eb106c","8JnvURhB4_vs","9f0af086","56bb4e66","wmcYRMj18sKz","s_NEOXw3JPo5"],"machine_shape":"hm","gpuType":"T4","toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}